# -*- coding: utf-8 -*-
"""face_recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oi_He2zfGTwOMU1BORAj4YL2ACmx4Vgg
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Conv2D,Flatten,BatchNormalization,Dropout,MaxPooling2D
import numpy as np
from tensorflow.keras import layers
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from random import shuffle
import cv2
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

from google.colab import files
uploaded = files.upload()

import zipfile
import os

!unzip /content/data.zip -d /content/

#create labels
dir = "/content/data"
folders = [entry.name for entry in os.scandir(dir) if entry.is_dir()]
folders = np.unique(folders)
print(folders)

label_encoder = LabelEncoder()
numerical_labels = label_encoder.fit_transform(folders)
labels_array = np.array(numerical_labels)
num_classes = len(np.unique(labels_array))
labels = to_categorical(labels_array, num_classes)

labels = zip(folders,labels)
labels = tuple(labels)

labels[0][1]

def data():
  data = []
  for f in folders:
    dir = f"/content/data/{f}"
    label = [i for i in labels if i[0] == str(f)]
    label = label[0][1]
    for img in os.listdir(dir):
      img_path = os.path.join(dir, img)
      img_data = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)
      img_data = cv2.resize(img_data,(256,256))
      data.append([np.array(img_data),label])
  shuffle(data)
  return data
dataset = data()

dataset[0][1]

images = np.array([item[0] for item in dataset])
labels = np.array([item[1] for item in dataset])

images = images.astype('float32') / 255.0

X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

y_train

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

X_train = np.expand_dims(X_train, axis=-1)
X_test = np.expand_dims(X_test, axis =-1)
train_generator = datagen.flow(X_train, y_train, batch_size=32)
test_generator = datagen.flow(X_test, y_test, batch_size=32)

model = Sequential()

model.add(layers.InputLayer(input_shape=(images.shape[1], images.shape[2],1)))
# Convolutional Block 1
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
model.add(MaxPooling2D((2, 2)))

# Convolutional Block 2
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
model.add(MaxPooling2D((2, 2)))

# Convolutional Block 3
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
model.add(MaxPooling2D((2, 2)))

# Fully Connected Block
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

# Output Layer
model.add(Dense(2, activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Summary of the model
model.summary()

history = model.fit(train_generator , epochs=10, batch_size=32,  validation_data=test_generator)

model.save('indentify.h5')

